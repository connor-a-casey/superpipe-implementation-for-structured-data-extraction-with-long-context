{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 1: building the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from superpipe.steps import LLMStructuredStep, CustomStep, SERPEnrichmentStep\n",
    "from superpipe import models\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Check if the SERPER API key is working correctly\n",
    "api_key = os.getenv(\"SERPER_API_KEY\")\n",
    "headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "\n",
    "query = {\"q\": \"test search\"}\n",
    "response = requests.get(\"https://api.serper.dev/search\", headers=headers, params=query)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"API key is working correctly.\")\n",
    "else:\n",
    "    print(f\"Error: API request failed with status code {response.status_code}\")\n",
    "    # You might want to exit the script or raise an exception here,\n",
    "    # as the pipeline steps won't work without a valid API key.\n",
    "    # For example, you can use:\n",
    "    # exit(1)\n",
    "    # or\n",
    "    # raise RuntimeError(f\"API request failed with status code {response.status_code}\")\n",
    "\n",
    "# Step 1: use Superpipe's built-in SERP enrichment step to search for the person's Wikipedia page\n",
    "# Include a unique \"name\" for the step that will be used to reference this step's output in future steps\n",
    "\n",
    "# Step 1: use Superpipe's built-in SERP enrichment step to search for the persons wikipedia page\n",
    "# Include a unique \"name\" for the step that will used to reference this step's output in future steps\n",
    "\n",
    "search_step = SERPEnrichmentStep(\n",
    "  prompt= lambda row: f\"{row['name']} wikipedia\",\n",
    "  name=\"search\"\n",
    ")\n",
    "\n",
    "# Step 2: Use an LLM to extract the wikipedia URL from the search results\n",
    "# First, define a Pydantic model that specifies the structured output we want from the LLM\n",
    "\n",
    "class ParseSearchResult(BaseModel):\n",
    "  wikipedia_url: str = Field(description=\"The URL of the Wikipedia page for the person\")\n",
    "\n",
    "# Then we use the built-in LLMStructuredStep and specify a model and a prompt\n",
    "# The prompt is a function that has access to all the fields in the input as well as the outputs of previous steps\n",
    "\n",
    "parse_search_step = LLMStructuredStep(\n",
    "  model=models.gpt35,\n",
    "  prompt= lambda row: f\"Extract the Wikipedia URL for {row['name']} from the following search results: \\n\\n {row['search']}\",\n",
    "  out_schema=ParseSearchResult,\n",
    "  name=\"parse_search\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Output: {'name': 'Jean-Paul Sartre', 'search': '{\"message\":\"Unauthorized. Sign up for a free account.\",\"statusCode\":403}'}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'wikipedia_url'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 77\u001b[0m\n\u001b[1;32m     69\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m     70\u001b[0m     search_step,\n\u001b[1;32m     71\u001b[0m     parse_search_step,\n\u001b[1;32m     72\u001b[0m     fetch_wikipedia_step,\n\u001b[1;32m     73\u001b[0m     extract_step\n\u001b[1;32m     74\u001b[0m ])\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Run the pipeline for a specific person\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mJean-Paul Sartre\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(output, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[0;32m~/Downloads/superpipe/.venv/lib/python3.10/site-packages/superpipe/pipeline.py:82\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, data, row_wise, verbose)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps:\n\u001b[0;32m---> 82\u001b[0m         \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m~/Downloads/superpipe/.venv/lib/python3.10/site-packages/superpipe/steps/step.py:139\u001b[0m, in \u001b[0;36mStep.run\u001b[0;34m(self, data, verbose)\u001b[0m\n\u001b[1;32m    137\u001b[0m     data[new_fields\u001b[38;5;241m.\u001b[39mcolumns] \u001b[38;5;241m=\u001b[39m new_fields\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 139\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_statistics(result\u001b[38;5;241m.\u001b[39mstatistics)\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd\u001b[38;5;241m.\u001b[39mSeries):\n",
      "File \u001b[0;32m~/Downloads/superpipe/.venv/lib/python3.10/site-packages/superpipe/steps/custom.py:51\u001b[0m, in \u001b[0;36mCustomStep._run\u001b[0;34m(self, row)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03mApplies the transformation function to a single row of data.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m    Dict: The transformed row, with keys corresponding to the fields defined in the `out_schema` Pydantic model.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m transform \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform\n\u001b[0;32m---> 51\u001b[0m transformed, statistics \u001b[38;5;241m=\u001b[39m \u001b[43mwith_statistics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m result \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: transformed}\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m StepResult(fields\u001b[38;5;241m=\u001b[39mresult, statistics\u001b[38;5;241m=\u001b[39mstatistics)\n",
      "File \u001b[0;32m~/Downloads/superpipe/.venv/lib/python3.10/site-packages/superpipe/steps/utils.py:38\u001b[0m, in \u001b[0;36mwith_statistics.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     37\u001b[0m     success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/Downloads/superpipe/.venv/lib/python3.10/site-packages/superpipe/steps/utils.py:31\u001b[0m, in \u001b[0;36mwith_statistics.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 31\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ShouldNotInterrupt:\n",
      "Cell \u001b[0;32mIn[56], line 48\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     38\u001b[0m parse_search_step \u001b[38;5;241m=\u001b[39m LLMStructuredStep(\n\u001b[1;32m     39\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodels\u001b[38;5;241m.\u001b[39mgpt35,\n\u001b[1;32m     40\u001b[0m     prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtract the Wikipedia URL for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from the following search results: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     41\u001b[0m     out_schema\u001b[38;5;241m=\u001b[39mParseSearchResult,\n\u001b[1;32m     42\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparse_search\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Step 3: Fetch Wikipedia content using the URL obtained from the search results\u001b[39;00m\n\u001b[1;32m     47\u001b[0m fetch_wikipedia_step \u001b[38;5;241m=\u001b[39m CustomStep(\n\u001b[0;32m---> 48\u001b[0m     transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m row: requests\u001b[38;5;241m.\u001b[39mget(\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwikipedia_url\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mtext,\n\u001b[1;32m     49\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfetch_wikipedia\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m )\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Step 4: Extract relevant data from the Wikipedia content\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mExtractedData\u001b[39;00m(BaseModel):\n",
      "\u001b[0;31mKeyError\u001b[0m: 'wikipedia_url'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from superpipe.steps import LLMStructuredStep, CustomStep, SERPEnrichmentStep\n",
    "from superpipe import models\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve serper.dev API key from environment variable\n",
    "SERPER_API_KEY = os.getenv('SERPER_API_KEY')\n",
    "\n",
    "# Step 1: use Superpipe's built-in SERP enrichment step to search for the person's Wikipedia page\n",
    "# Include a unique \"name\" for the step that will be used to reference this step's output in future steps\n",
    "\n",
    "# Define a function to perform SERP enrichment with custom headers\n",
    "def custom_serp_enrichment(row):\n",
    "    url = \"https://api.serper.dev/serp\"\n",
    "    headers = {'x-api-key': SERPER_API_KEY}\n",
    "    params = {'q': f\"{row['name']} wikipedia\"}\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    return response.json()\n",
    "\n",
    "search_step = SERPEnrichmentStep(\n",
    "    prompt=custom_serp_enrichment,\n",
    "    name=\"search\"\n",
    ")\n",
    "print(\"Search Output:\", search_output)\n",
    "\n",
    "\n",
    "# Step 2: Use an LLM to extract the Wikipedia URL from the search results\n",
    "# First, define a Pydantic model that specifies the structured output we want from the LLM\n",
    "\n",
    "class ParseSearchResult(BaseModel):\n",
    "    wikipedia_url: str = Field(description=\"The URL of the Wikipedia page for the person\")\n",
    "\n",
    "parse_search_step = LLMStructuredStep(\n",
    "    model=models.gpt35,\n",
    "    prompt=lambda row: f\"Extract the Wikipedia URL for {row['name']} from the following search results: \\n\\n {row['search']}\",\n",
    "    out_schema=ParseSearchResult,\n",
    "    name=\"parse_search\"\n",
    ")\n",
    "\n",
    "# Step 3: Fetch Wikipedia content using the URL obtained from the search results\n",
    "\n",
    "fetch_wikipedia_step = CustomStep(\n",
    "    transform=lambda row: requests.get(row['wikipedia_url']).text,\n",
    "    name=\"fetch_wikipedia\"\n",
    ")\n",
    "\n",
    "# Step 4: Extract relevant data from the Wikipedia content\n",
    "\n",
    "class ExtractedData(BaseModel):\n",
    "    date_of_birth: str = Field(description=\"The date of birth of the person in the format YYYY-MM-DD\")\n",
    "    alive: bool = Field(description=\"Whether the person is still alive\")\n",
    "    cause_of_death: str = Field(description=\"The cause of death of the person. If the person is alive, return 'N/A'\")\n",
    "\n",
    "extract_step = LLMStructuredStep(\n",
    "    model=models.gpt4,\n",
    "    prompt=lambda row: f\"\"\"Extract the date of birth for {row['name']}, whether they're still alive \\\n",
    "    and if not, their cause of death from the following Wikipedia content: \\n\\n {row['wikipedia']}\"\"\",\n",
    "    out_schema=ExtractedData,\n",
    "    name=\"extract_data\"\n",
    ")\n",
    "\n",
    "# Define and run the pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    search_step,\n",
    "    parse_search_step,\n",
    "    fetch_wikipedia_step,\n",
    "    extract_step\n",
    "])\n",
    "\n",
    "# Run the pipeline for a specific person\n",
    "output = pipeline.run({\"name\": \"Jean-Paul Sartre\"})\n",
    "print(json.dumps(output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 2: evaluating the pipeline [TBD}]\n",
    "\n",
    "broken into the folliowing parts:\n",
    "\n",
    "1. **a dataset with labels** - in this case we need a list of famous people and the true date of birth, living status and cause of death of each person\n",
    "2. **evaluation function** - a function that defines what \"correct\" is. We'll use simple comparison for date of birth and living status, and an LLM call to evaluate the correctness of cause of death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = [\n",
    "  (\"Ruth Bader Ginsburg\", \"1933-03-15\", False, \"Pancreatic cancer\"),\n",
    "  (\"Bill Gates\", \"1955-10-28\", True, \"N/A\"),\n",
    "  (\"Steph Curry\", \"1988-03-14\", True, \"N/A\"),\n",
    "  (\"Scott Belsky\", \"1980-04-18\", True, \"N/A\"),\n",
    "  (\"Steve Jobs\", \"1955-02-24\", False, \"Pancreatic tumor/cancer\"),\n",
    "  (\"Paris Hilton\", \"1981-02-17\", True, \"N/A\"),\n",
    "  (\"Kurt Vonnegut\", \"1922-11-11\", False, \"Brain injuries\"),\n",
    "  (\"Snoop Dogg\", \"1971-10-20\", True, \"N/A\"),\n",
    "  (\"Kobe Bryant\", \"1978-08-23\", False, \"Helicopter crash\"),\n",
    "  (\"Aaron Swartz\", \"1986-11-08\", False, \"Suicide\")\n",
    "]\n",
    "df = pd.DataFrame([{\"name\": d[0], \"dob_label\": d[1], \"alive_label\": d[2], \"cause_label\": d[3]} for d in data])\n",
    "\n",
    "class EvalResult(BaseModel):\n",
    "  result: bool = Field(description=\"Is the answer correct or not?\")\n",
    "\n",
    "cause_evaluator = LLMStructuredStep(\n",
    "  model=models.gpt4,\n",
    "  prompt=lambda row: f\"This is the correct cause of death: {row['cause_label']}. Is this provided cause of death accurate? The phrasing might be slightly different. Use your judgement: \\n{row['cause_of_death']}\",\n",
    "  out_schema=EvalResult,\n",
    "  name=\"cause_evaluator\")\n",
    "\n",
    "def eval_fn(row):\n",
    "  score = 0\n",
    "  if row['date_of_birth'] == row['dob_label']:\n",
    "    score += 0.25\n",
    "  if row['alive'] == row['alive_label']:\n",
    "    score += 0.25\n",
    "  if row['cause_label'] == \"N/A\":\n",
    "    if row['cause_of_death'] == \"N/A\":\n",
    "      score += 0.5\n",
    "  elif cause_evaluator.run(row)['result']:\n",
    "    score += 0.5  \n",
    "  return score\n",
    "\n",
    "pipeline.run(df)\n",
    "print(\"Score: \", pipeline.evaluate(eval_fn))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 3: optimizing the pipeline\n",
    "\n",
    "this pipeline has an accuracy score of 100%, but perhaps there's room for improvement on cost and speed. First let's view the cost and latency of each step to figure out which one is the bottleneck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in pipeline.steps:\n",
    "  print(f\"Step {step.name}:\")\n",
    "  print(f\"- Latency: {step.statistics.total_latency}\")\n",
    "  print(f\"- Cost: {step.statistics.input_cost + step.statistics.output_cost}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the final step (`extract_data`) is the one responsible for the bulk of the cost and latency. This makes sense, because we're feeding in the entire wikipedia article to GPT-4, one of the most expensive models.\n",
    "\n",
    "Let's find out if we can get away with a cheaper/faster model. Most models cannot handle the number of tokens needed to ingest a whole wikipedia article, so we'll turn to the two that can that are also cheaper than GPT4: Claude 3 Sonnet and Claude 3 Haiku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from superpipe.grid_search import GridSearch\n",
    "from superpipe.models import claude3_haiku, claude3_sonnet\n",
    "from superpipe.steps import LLMStructuredCompositeStep\n",
    "\n",
    "# we need to use LLMStructuredCompositeStep which uses GPT3.5 for structured JSON extraction\n",
    "# because Claude does not support JSON mode or function calling out of the box\n",
    "new_extract_step = LLMStructuredCompositeStep(\n",
    "  model=models.claude3_haiku,\n",
    "  prompt=extract_step.prompt,\n",
    "  out_schema=ExtractedData,\n",
    "  name=\"extract_data_new\"\n",
    ")\n",
    "\n",
    "new_pipeline = Pipeline([\n",
    "  search_step,\n",
    "  parse_search_step,\n",
    "  fetch_wikipedia_step,\n",
    "  new_extract_step\n",
    "], evaluation_fn=eval_fn)\n",
    "\n",
    "param_grid = {\n",
    "  new_extract_step.name:{\n",
    "    \"model\": [claude3_haiku, claude3_sonnet]}\n",
    "}\n",
    "grid_search = GridSearch(new_pipeline, param_grid)\n",
    "grid_search.run(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strangely, Claude 3 Haiku is both more accurate (100% v/s 45%) as well as cheaper and faster. This is suprising, but useful information that we wouldn't have found out unless we built and evaluated pipelines on _our specific data_ rather than benchmark data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params\n",
    "new_pipeline.update_params(best_params)\n",
    "new_pipeline.run(df)\n",
    "print(\"Score: \", new_pipeline.score)\n",
    "for step in new_pipeline.steps:\n",
    "  print(f\"Step {step.name}:\")\n",
    "  print(f\"- Latency: {step.statistics.total_latency}\")\n",
    "  print(f\"- Cost: {step.statistics.input_cost + step.statistics.output_cost}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
